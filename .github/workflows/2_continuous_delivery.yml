name: 2 - Continuous Delivery
run-name: "${{ github.workflow }}"

permissions: write-all

on:
  # Runs when the previous stage finished
  workflow_run:
    workflows: ["1 - Continuous Integration"]
    types: [completed]

  workflow_dispatch:

env:
  REGISTRY: ${{ vars.REGISTRY }}
  MLFLOW_TRACKING_URI: ${{ vars.MLFLOW_TRACKING_URI }}
  MLFLOW_EXPERIMENT_NAME: ${{ vars.MLFLOW_EXPERIMENT_NAME }}
  MLFLOW_MODEL_NAME: ${{ vars.MLFLOW_MODEL_NAME }}

jobs:
  train-model:
    # Run only if previous stage finished successfully (for automatic trigger) OR if manually triggered
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'workflow_dispatch' }}
    runs-on: self-hosted

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: "3.13" }
      - name: Setup python environment
        run: |
          pip install uv
          uv sync

      # Download workflow config from previous workflow (only for automatic triggers)
      - name: Download workflow config
        if: ${{ github.event_name == 'workflow_run' }}
        uses: actions/download-artifact@v4
        with:
          name: workflow-config-${{ github.sha }}
          path: workflow-config/
          github-token: ${{ secrets.GITHUB_TOKEN }}
          run-id: ${{ github.event.workflow_run.id }}
          continue-on-error: true

      - name: Set skip_training flag
        id: config
        run: |
          if [ -f workflow-config/skip_training.txt ]; then
            SKIP_TRAINING=$(cat workflow-config/skip_training.txt)
            echo "skip_training=$SKIP_TRAINING" >> $GITHUB_OUTPUT
          else
            # For manual triggers, always skip training since models image may not have latest code
            echo "skip_training=true" >> $GITHUB_OUTPUT
          fi
          echo "Skip training: $(cat workflow-config/skip_training.txt 2>/dev/null || echo 'true (manual trigger default)')"

      # Log in to GitHub Container Registry (GHCR)
      # We will get the serving image with tag staging from here to validate
      - uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      # Download models image built in the previous stage
      - name: Pull models image
        run: docker pull ${{ env.REGISTRY }}/${{ github.repository }}/models:${{ github.sha }}

      - name: Create OVPN file
        run: echo "${{ secrets.OVPN_CONFIG_FILE }}" > DEI.ovpn

      - name: Connect to VPN
        uses: "kota65535/github-openvpn-connect-action@v3"
        with:
          config_file: DEI.ovpn
          username: ${{ secrets.OVPN_USERNAME }}
          password: ${{ secrets.OVPN_PASSWORD }}

      - name: Ping test
        run: |
          set -x
          ping -c 4 ${{ secrets.SERVING_VM_HOST }} || echo "ping failed with code $?"

      # Run models container which runs the models script within
      # The models script will select the "best" model and tag it with the sha of the commit in mlflow
      - name: Run models
        env:
          MLFLOW_TRACKING_URI: ${{ env.MLFLOW_TRACKING_URI }}
          MLFLOW_EXPERIMENT_NAME: ${{ env.MLFLOW_EXPERIMENT_NAME }}
          MLFLOW_MODEL_NAME: ${{ env.MLFLOW_MODEL_NAME }}
          COMMIT_SHA: ${{ github.sha }}
        run: |
          if [ "${{ steps.config.outputs.skip_training }}" = "true" ]; then
            SKIP_ARG="--skip-training"
          else
            SKIP_ARG=""
          fi
          docker run --rm \
            --network host \
            -e MLFLOW_TRACKING_URI \
            -e MLFLOW_MODEL_NAME \
            -e MLFLOW_EXPERIMENT_NAME \
            -e COMMIT_SHA \
            -v ~/data:/app/data \
            ${{ env.REGISTRY }}/${{ github.repository }}/models:${{ github.sha }} \
            bash -c "uv run python preprocess.py --train-size 100000 && uv run python run_all_models.py $SKIP_ARG"

      # Download serving image built in the previous stage
      - name: Pull serving image
        run: docker pull ${{ env.REGISTRY }}/${{ github.repository }}/serving:${{ github.sha }}

      # Start serving image
      # It is configured to load the model passed in env variable MLFLOW_MODEL_NAME and alias MODEL_ALIAS
      - name: Start serving container
        env:
          MLFLOW_TRACKING_URI: ${{ env.MLFLOW_TRACKING_URI }}
          MODEL_ALIAS: ${{ github.sha }}
          MLFLOW_MODEL_NAME: ${{ env.MLFLOW_MODEL_NAME }}
        run: |
          docker run -d \
            --name serving-app \
            --network host \
            -e MLFLOW_TRACKING_URI \
            -e MODEL_ALIAS \
            -e MLFLOW_MODEL_NAME \
            ${{ env.REGISTRY }}/${{ github.repository }}/serving:${{ github.sha }}

          # Wait for FastAPI to be ready
          sleep 10

      # Run end to end tests, this will test the serving app to see if it is working ok
      # Additional metrics and verification can assess performance metrics as well
      - name: Run Staging tests
        run: uv run pytest tests/test_e2e.py -v

      - name: Show container logs on failure
        if: failure()
        run: |
          echo "=== FastAPI logs ==="
          docker logs serving-app || true

      # Log in to GitHub Container Registry (GHCR)
      # This is the repository where we will upload our images once they have been validated
      - uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      # Tag serving image with staging; this image will be used for further testing in staging
      # Push serving image to repository
      - name: Push serving staging image
        run: |
          docker tag ${{ env.REGISTRY }}/${{ github.repository }}/serving:${{ github.sha }} \
                     ${{ env.REGISTRY }}/${{ github.repository }}/serving:staging
          docker push ${{ env.REGISTRY }}/${{ github.repository }}/serving:staging

      # Promote selected model to staging to be further validated
      # The script will look for the MLFLOW_MODEL_NAME and promote it from FROM_ALIAS to TO_ALIAS
      - name: Promote model to staging
        env:
          MLFLOW_TRACKING_URI: ${{ env.MLFLOW_TRACKING_URI }}
          MLFLOW_EXPERIMENT_NAME: ${{ env.MLFLOW_EXPERIMENT_NAME }}
          MLFLOW_MODEL_NAME: ${{ env.MLFLOW_MODEL_NAME }}
          FROM_ALIAS: ${{ github.sha }}
          TO_ALIAS: staging
        run: |
          set -xe
          uv run python -u model-promotion/promote_model.py
